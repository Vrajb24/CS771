{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-30 16:13:35.632820: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-30 16:13:35.633168: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 16:13:35.635187: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-30 16:13:35.641671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-30 16:13:35.650412: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-30 16:13:35.652851: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-30 16:13:35.659996: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-30 16:13:36.166496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Keras libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "emoticon_data = pd.read_csv(\"/home/belief/Desktop/MLProj1/mini-project-1/datasets/train/train_emoticon.csv\")\n",
    "emoticon_data['split_emoticons'] = emoticon_data['input_emoticon'].apply(list)\n",
    "\n",
    "# Remove the 'input_emoticon' column\n",
    "emoticon_data = emoticon_data.drop('input_emoticon', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data encoding\n",
    "df = emoticon_data\n",
    "mlb = MultiLabelBinarizer()\n",
    "emoji_encoded = mlb.fit_transform(df['split_emoticons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded emojis\n",
    "emoji_df = pd.DataFrame(emoji_encoded, columns=mlb.classes_)\n",
    "\n",
    "# Concatenate the label column with the encoded emojis\n",
    "final_df = pd.concat([emoji_df, df['label']], axis=1)\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = final_df.drop('label', axis=1)\n",
    "y = final_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to categorical values\n",
    "y_train_cat = tf.keras.utils.to_categorical(y_train, num_classes=len(y.unique()))\n",
    "y_test_cat = tf.keras.utils.to_categorical(y_test, num_classes=len(y.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/belief/Desktop/MLProj1/MLProj1env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network model using Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))  # Input layer and first hidden layer\n",
    "model.add(Dense(64, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(y_train_cat.shape[1], activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.4919 - loss: 0.6995 - val_accuracy: 0.4866 - val_loss: 0.6944\n",
      "Epoch 2/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.5306 - loss: 0.6906 - val_accuracy: 0.4951 - val_loss: 0.6967\n",
      "Epoch 3/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.5625 - loss: 0.6827 - val_accuracy: 0.4936 - val_loss: 0.7023\n",
      "Epoch 4/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.5830 - loss: 0.6732 - val_accuracy: 0.4816 - val_loss: 0.7066\n",
      "Epoch 5/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.6264 - loss: 0.6556 - val_accuracy: 0.4781 - val_loss: 0.7300\n",
      "Epoch 6/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.6559 - loss: 0.6322 - val_accuracy: 0.4605 - val_loss: 0.7658\n",
      "Epoch 7/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.7097 - loss: 0.5718 - val_accuracy: 0.4767 - val_loss: 0.8011\n",
      "Epoch 8/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 516us/step - accuracy: 0.7810 - loss: 0.4890 - val_accuracy: 0.4732 - val_loss: 0.9055\n",
      "Epoch 9/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.8389 - loss: 0.3915 - val_accuracy: 0.4492 - val_loss: 1.0212\n",
      "Epoch 10/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.8728 - loss: 0.3314 - val_accuracy: 0.4555 - val_loss: 1.1695\n",
      "Epoch 11/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9183 - loss: 0.2461 - val_accuracy: 0.4492 - val_loss: 1.3642\n",
      "Epoch 12/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9484 - loss: 0.1740 - val_accuracy: 0.4612 - val_loss: 1.5722\n",
      "Epoch 13/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9559 - loss: 0.1398 - val_accuracy: 0.4393 - val_loss: 1.7857\n",
      "Epoch 14/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9792 - loss: 0.0933 - val_accuracy: 0.4442 - val_loss: 1.9666\n",
      "Epoch 15/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9872 - loss: 0.0710 - val_accuracy: 0.4513 - val_loss: 2.2195\n",
      "Epoch 16/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9890 - loss: 0.0562 - val_accuracy: 0.4357 - val_loss: 2.4199\n",
      "Epoch 17/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.9951 - loss: 0.0368 - val_accuracy: 0.4442 - val_loss: 2.5470\n",
      "Epoch 18/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9895 - loss: 0.0478 - val_accuracy: 0.4492 - val_loss: 2.6678\n",
      "Epoch 19/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9959 - loss: 0.0317 - val_accuracy: 0.4470 - val_loss: 2.8415\n",
      "Epoch 20/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9976 - loss: 0.0247 - val_accuracy: 0.4456 - val_loss: 2.9561\n",
      "Epoch 21/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9958 - loss: 0.0266 - val_accuracy: 0.4371 - val_loss: 3.0670\n",
      "Epoch 22/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9945 - loss: 0.0276 - val_accuracy: 0.4463 - val_loss: 3.2076\n",
      "Epoch 23/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9905 - loss: 0.0313 - val_accuracy: 0.4386 - val_loss: 3.3032\n",
      "Epoch 24/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9963 - loss: 0.0216 - val_accuracy: 0.4421 - val_loss: 3.4688\n",
      "Epoch 25/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9922 - loss: 0.0322 - val_accuracy: 0.4428 - val_loss: 3.4776\n",
      "Epoch 26/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9942 - loss: 0.0250 - val_accuracy: 0.4477 - val_loss: 3.4446\n",
      "Epoch 27/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9914 - loss: 0.0311 - val_accuracy: 0.4428 - val_loss: 3.8379\n",
      "Epoch 28/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9842 - loss: 0.0458 - val_accuracy: 0.4322 - val_loss: 3.5096\n",
      "Epoch 29/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9904 - loss: 0.0323 - val_accuracy: 0.4421 - val_loss: 3.6877\n",
      "Epoch 30/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9967 - loss: 0.0195 - val_accuracy: 0.4322 - val_loss: 3.6892\n",
      "Epoch 31/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9980 - loss: 0.0120 - val_accuracy: 0.4449 - val_loss: 3.7514\n",
      "Epoch 32/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9942 - loss: 0.0187 - val_accuracy: 0.4294 - val_loss: 3.8540\n",
      "Epoch 33/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.9955 - loss: 0.0196 - val_accuracy: 0.4393 - val_loss: 3.8394\n",
      "Epoch 34/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.9940 - loss: 0.0248 - val_accuracy: 0.4350 - val_loss: 4.0037\n",
      "Epoch 35/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - accuracy: 0.9955 - loss: 0.0186 - val_accuracy: 0.4315 - val_loss: 3.9504\n",
      "Epoch 36/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9975 - loss: 0.0126 - val_accuracy: 0.4386 - val_loss: 4.0312\n",
      "Epoch 37/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9937 - loss: 0.0266 - val_accuracy: 0.4315 - val_loss: 3.8734\n",
      "Epoch 38/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9928 - loss: 0.0255 - val_accuracy: 0.4280 - val_loss: 3.8962\n",
      "Epoch 39/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9977 - loss: 0.0134 - val_accuracy: 0.4371 - val_loss: 4.0489\n",
      "Epoch 40/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9953 - loss: 0.0225 - val_accuracy: 0.4301 - val_loss: 4.0522\n",
      "Epoch 41/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9915 - loss: 0.0317 - val_accuracy: 0.4315 - val_loss: 4.3569\n",
      "Epoch 42/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9953 - loss: 0.0206 - val_accuracy: 0.4393 - val_loss: 4.0508\n",
      "Epoch 43/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9939 - loss: 0.0220 - val_accuracy: 0.4258 - val_loss: 4.1621\n",
      "Epoch 44/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9954 - loss: 0.0171 - val_accuracy: 0.4301 - val_loss: 4.1763\n",
      "Epoch 45/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9975 - loss: 0.0095 - val_accuracy: 0.4329 - val_loss: 4.2900\n",
      "Epoch 46/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9974 - loss: 0.0118 - val_accuracy: 0.4308 - val_loss: 4.2742\n",
      "Epoch 47/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.4294 - val_loss: 4.2341\n",
      "Epoch 48/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.9968 - loss: 0.0112 - val_accuracy: 0.4244 - val_loss: 4.5456\n",
      "Epoch 49/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9951 - loss: 0.0173 - val_accuracy: 0.4421 - val_loss: 4.4208\n",
      "Epoch 50/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9970 - loss: 0.0114 - val_accuracy: 0.4364 - val_loss: 4.5212\n",
      "Epoch 51/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9938 - loss: 0.0215 - val_accuracy: 0.4308 - val_loss: 4.4270\n",
      "Epoch 52/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9897 - loss: 0.0303 - val_accuracy: 0.4492 - val_loss: 4.3664\n",
      "Epoch 53/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9944 - loss: 0.0172 - val_accuracy: 0.4301 - val_loss: 4.4978\n",
      "Epoch 54/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9958 - loss: 0.0143 - val_accuracy: 0.4336 - val_loss: 4.4217\n",
      "Epoch 55/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9962 - loss: 0.0148 - val_accuracy: 0.4350 - val_loss: 4.4823\n",
      "Epoch 56/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9952 - loss: 0.0126 - val_accuracy: 0.4336 - val_loss: 4.4795\n",
      "Epoch 57/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 532us/step - accuracy: 0.9972 - loss: 0.0108 - val_accuracy: 0.4287 - val_loss: 4.6919\n",
      "Epoch 58/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9973 - loss: 0.0099 - val_accuracy: 0.4308 - val_loss: 4.5945\n",
      "Epoch 59/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 467us/step - accuracy: 0.9974 - loss: 0.0100 - val_accuracy: 0.4266 - val_loss: 4.6992\n",
      "Epoch 60/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.9952 - loss: 0.0161 - val_accuracy: 0.4350 - val_loss: 4.6115\n",
      "Epoch 61/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9959 - loss: 0.0141 - val_accuracy: 0.4371 - val_loss: 4.5367\n",
      "Epoch 62/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9914 - loss: 0.0218 - val_accuracy: 0.4336 - val_loss: 4.4107\n",
      "Epoch 63/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9953 - loss: 0.0162 - val_accuracy: 0.4322 - val_loss: 4.7426\n",
      "Epoch 64/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 0.4414 - val_loss: 4.7948\n",
      "Epoch 65/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9963 - loss: 0.0107 - val_accuracy: 0.4266 - val_loss: 4.9038\n",
      "Epoch 66/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.9969 - loss: 0.0081 - val_accuracy: 0.4393 - val_loss: 4.8346\n",
      "Epoch 67/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.9957 - loss: 0.0106 - val_accuracy: 0.4350 - val_loss: 4.8613\n",
      "Epoch 68/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9959 - loss: 0.0116 - val_accuracy: 0.4393 - val_loss: 4.4728\n",
      "Epoch 69/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9896 - loss: 0.0281 - val_accuracy: 0.4400 - val_loss: 4.4166\n",
      "Epoch 70/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9936 - loss: 0.0171 - val_accuracy: 0.4435 - val_loss: 4.6231\n",
      "Epoch 71/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9957 - loss: 0.0117 - val_accuracy: 0.4414 - val_loss: 4.8195\n",
      "Epoch 72/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.9983 - loss: 0.0082 - val_accuracy: 0.4400 - val_loss: 4.8228\n",
      "Epoch 73/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.4357 - val_loss: 4.9009\n",
      "Epoch 74/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9965 - loss: 0.0087 - val_accuracy: 0.4421 - val_loss: 4.8694\n",
      "Epoch 75/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.4421 - val_loss: 4.7954\n",
      "Epoch 76/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9967 - loss: 0.0065 - val_accuracy: 0.4379 - val_loss: 4.9567\n",
      "Epoch 77/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9981 - loss: 0.0047 - val_accuracy: 0.4506 - val_loss: 4.6936\n",
      "Epoch 78/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.4371 - val_loss: 4.7437\n",
      "Epoch 79/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9941 - loss: 0.0156 - val_accuracy: 0.4421 - val_loss: 4.4468\n",
      "Epoch 80/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9872 - loss: 0.0375 - val_accuracy: 0.4336 - val_loss: 4.8985\n",
      "Epoch 81/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9959 - loss: 0.0106 - val_accuracy: 0.4336 - val_loss: 4.8891\n",
      "Epoch 82/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - accuracy: 0.9971 - loss: 0.0061 - val_accuracy: 0.4386 - val_loss: 5.0565\n",
      "Epoch 83/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.9968 - loss: 0.0058 - val_accuracy: 0.4357 - val_loss: 5.1683\n",
      "Epoch 84/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9978 - loss: 0.0056 - val_accuracy: 0.4371 - val_loss: 5.2059\n",
      "Epoch 85/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.4343 - val_loss: 5.2274\n",
      "Epoch 86/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.4364 - val_loss: 5.2201\n",
      "Epoch 87/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.4357 - val_loss: 5.1960\n",
      "Epoch 88/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9979 - loss: 0.0046 - val_accuracy: 0.4357 - val_loss: 5.1454\n",
      "Epoch 89/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 501us/step - accuracy: 0.9964 - loss: 0.0063 - val_accuracy: 0.4343 - val_loss: 5.0352\n",
      "Epoch 90/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9974 - loss: 0.0058 - val_accuracy: 0.4350 - val_loss: 5.1722\n",
      "Epoch 91/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9986 - loss: 0.0033 - val_accuracy: 0.4336 - val_loss: 5.0243\n",
      "Epoch 92/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9979 - loss: 0.0044 - val_accuracy: 0.4336 - val_loss: 4.9840\n",
      "Epoch 93/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9974 - loss: 0.0047 - val_accuracy: 0.4308 - val_loss: 5.0242\n",
      "Epoch 94/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.4308 - val_loss: 5.1705\n",
      "Epoch 95/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9971 - loss: 0.0049 - val_accuracy: 0.4393 - val_loss: 5.0712\n",
      "Epoch 96/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9984 - loss: 0.0036 - val_accuracy: 0.4308 - val_loss: 5.0500\n",
      "Epoch 97/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9971 - loss: 0.0055 - val_accuracy: 0.4315 - val_loss: 5.1099\n",
      "Epoch 98/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - accuracy: 0.9968 - loss: 0.0047 - val_accuracy: 0.4350 - val_loss: 5.3106\n",
      "Epoch 99/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9967 - loss: 0.0052 - val_accuracy: 0.4379 - val_loss: 5.2592\n",
      "Epoch 100/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - accuracy: 0.9971 - loss: 0.0051 - val_accuracy: 0.4336 - val_loss: 5.1957\n",
      "Epoch 101/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9969 - loss: 0.0051 - val_accuracy: 0.4357 - val_loss: 5.2736\n",
      "Epoch 102/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9980 - loss: 0.0036 - val_accuracy: 0.4421 - val_loss: 5.4113\n",
      "Epoch 103/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9979 - loss: 0.0030 - val_accuracy: 0.4329 - val_loss: 5.3306\n",
      "Epoch 104/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9969 - loss: 0.0041 - val_accuracy: 0.4400 - val_loss: 5.3807\n",
      "Epoch 105/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9973 - loss: 0.0045 - val_accuracy: 0.4379 - val_loss: 5.4350\n",
      "Epoch 106/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9896 - loss: 0.0285 - val_accuracy: 0.4308 - val_loss: 4.4422\n",
      "Epoch 107/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9833 - loss: 0.0511 - val_accuracy: 0.4407 - val_loss: 4.6765\n",
      "Epoch 108/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9921 - loss: 0.0162 - val_accuracy: 0.4379 - val_loss: 4.9749\n",
      "Epoch 109/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9970 - loss: 0.0058 - val_accuracy: 0.4386 - val_loss: 5.1382\n",
      "Epoch 110/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9974 - loss: 0.0039 - val_accuracy: 0.4400 - val_loss: 5.3045\n",
      "Epoch 111/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9964 - loss: 0.0043 - val_accuracy: 0.4414 - val_loss: 5.3483\n",
      "Epoch 112/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9971 - loss: 0.0036 - val_accuracy: 0.4379 - val_loss: 5.3606\n",
      "Epoch 113/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9959 - loss: 0.0044 - val_accuracy: 0.4407 - val_loss: 5.4304\n",
      "Epoch 114/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - accuracy: 0.9974 - loss: 0.0038 - val_accuracy: 0.4379 - val_loss: 5.4440\n",
      "Epoch 115/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - accuracy: 0.9947 - loss: 0.0056 - val_accuracy: 0.4357 - val_loss: 5.4736\n",
      "Epoch 116/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - accuracy: 0.9967 - loss: 0.0031 - val_accuracy: 0.4371 - val_loss: 5.5167\n",
      "Epoch 117/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9968 - loss: 0.0040 - val_accuracy: 0.4414 - val_loss: 5.5791\n",
      "Epoch 118/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9980 - loss: 0.0030 - val_accuracy: 0.4386 - val_loss: 5.5596\n",
      "Epoch 119/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - accuracy: 0.9977 - loss: 0.0034 - val_accuracy: 0.4428 - val_loss: 5.5920\n",
      "Epoch 120/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9983 - loss: 0.0026 - val_accuracy: 0.4393 - val_loss: 5.5844\n",
      "Epoch 121/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9977 - loss: 0.0030 - val_accuracy: 0.4364 - val_loss: 5.5781\n",
      "Epoch 122/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - accuracy: 0.9963 - loss: 0.0050 - val_accuracy: 0.4357 - val_loss: 5.6171\n",
      "Epoch 123/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9989 - loss: 0.0022 - val_accuracy: 0.4421 - val_loss: 5.6004\n",
      "Epoch 124/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9966 - loss: 0.0038 - val_accuracy: 0.4428 - val_loss: 5.6249\n",
      "Epoch 125/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.9982 - loss: 0.0030 - val_accuracy: 0.4343 - val_loss: 5.7068\n",
      "Epoch 126/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9969 - loss: 0.0035 - val_accuracy: 0.4393 - val_loss: 5.6455\n",
      "Epoch 127/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9981 - loss: 0.0027 - val_accuracy: 0.4428 - val_loss: 5.5865\n",
      "Epoch 128/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9968 - loss: 0.0036 - val_accuracy: 0.4357 - val_loss: 5.7684\n",
      "Epoch 129/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9981 - loss: 0.0029 - val_accuracy: 0.4407 - val_loss: 5.6769\n",
      "Epoch 130/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9966 - loss: 0.0047 - val_accuracy: 0.4386 - val_loss: 5.7901\n",
      "Epoch 131/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9973 - loss: 0.0038 - val_accuracy: 0.4470 - val_loss: 6.1461\n",
      "Epoch 132/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9666 - loss: 0.1029 - val_accuracy: 0.4386 - val_loss: 4.4019\n",
      "Epoch 133/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9915 - loss: 0.0246 - val_accuracy: 0.4280 - val_loss: 4.9506\n",
      "Epoch 134/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9969 - loss: 0.0048 - val_accuracy: 0.4251 - val_loss: 5.2788\n",
      "Epoch 135/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9968 - loss: 0.0045 - val_accuracy: 0.4301 - val_loss: 5.3475\n",
      "Epoch 136/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9982 - loss: 0.0027 - val_accuracy: 0.4322 - val_loss: 5.3908\n",
      "Epoch 137/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9977 - loss: 0.0032 - val_accuracy: 0.4308 - val_loss: 5.4832\n",
      "Epoch 138/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9984 - loss: 0.0027 - val_accuracy: 0.4280 - val_loss: 5.4964\n",
      "Epoch 139/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9960 - loss: 0.0047 - val_accuracy: 0.4329 - val_loss: 5.5524\n",
      "Epoch 140/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step - accuracy: 0.9958 - loss: 0.0046 - val_accuracy: 0.4251 - val_loss: 5.5962\n",
      "Epoch 141/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9965 - loss: 0.0043 - val_accuracy: 0.4301 - val_loss: 5.6295\n",
      "Epoch 142/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - accuracy: 0.9981 - loss: 0.0027 - val_accuracy: 0.4266 - val_loss: 5.5760\n",
      "Epoch 143/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9974 - loss: 0.0034 - val_accuracy: 0.4329 - val_loss: 5.5505\n",
      "Epoch 144/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9960 - loss: 0.0041 - val_accuracy: 0.4322 - val_loss: 5.6336\n",
      "Epoch 145/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9965 - loss: 0.0039 - val_accuracy: 0.4294 - val_loss: 5.6954\n",
      "Epoch 146/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9964 - loss: 0.0034 - val_accuracy: 0.4244 - val_loss: 5.7375\n",
      "Epoch 147/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9973 - loss: 0.0041 - val_accuracy: 0.4308 - val_loss: 5.8251\n",
      "Epoch 148/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9975 - loss: 0.0037 - val_accuracy: 0.4315 - val_loss: 5.7853\n",
      "Epoch 149/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9971 - loss: 0.0033 - val_accuracy: 0.4336 - val_loss: 5.7721\n",
      "Epoch 150/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9975 - loss: 0.0028 - val_accuracy: 0.4357 - val_loss: 5.7473\n",
      "Epoch 151/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9981 - loss: 0.0035 - val_accuracy: 0.4350 - val_loss: 5.8477\n",
      "Epoch 152/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9976 - loss: 0.0026 - val_accuracy: 0.4336 - val_loss: 5.8961\n",
      "Epoch 153/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - accuracy: 0.9976 - loss: 0.0030 - val_accuracy: 0.4364 - val_loss: 5.8708\n",
      "Epoch 154/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 464us/step - accuracy: 0.9926 - loss: 0.0181 - val_accuracy: 0.4343 - val_loss: 3.5466\n",
      "Epoch 155/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9816 - loss: 0.0493 - val_accuracy: 0.4329 - val_loss: 5.0140\n",
      "Epoch 156/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 461us/step - accuracy: 0.9935 - loss: 0.0135 - val_accuracy: 0.4386 - val_loss: 5.1921\n",
      "Epoch 157/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9956 - loss: 0.0058 - val_accuracy: 0.4251 - val_loss: 5.4172\n",
      "Epoch 158/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - accuracy: 0.9964 - loss: 0.0047 - val_accuracy: 0.4266 - val_loss: 5.4500\n",
      "Epoch 159/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9984 - loss: 0.0030 - val_accuracy: 0.4280 - val_loss: 5.5384\n",
      "Epoch 160/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9980 - loss: 0.0032 - val_accuracy: 0.4258 - val_loss: 5.5941\n",
      "Epoch 161/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - accuracy: 0.9971 - loss: 0.0031 - val_accuracy: 0.4266 - val_loss: 5.6484\n",
      "Epoch 162/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9984 - loss: 0.0021 - val_accuracy: 0.4244 - val_loss: 5.7307\n",
      "Epoch 163/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9967 - loss: 0.0034 - val_accuracy: 0.4287 - val_loss: 5.7197\n",
      "Epoch 164/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.9984 - loss: 0.0037 - val_accuracy: 0.4280 - val_loss: 5.7714\n",
      "Epoch 165/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9984 - loss: 0.0031 - val_accuracy: 0.4287 - val_loss: 5.8101\n",
      "Epoch 166/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9968 - loss: 0.0033 - val_accuracy: 0.4273 - val_loss: 5.8510\n",
      "Epoch 167/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9980 - loss: 0.0028 - val_accuracy: 0.4251 - val_loss: 5.9174\n",
      "Epoch 168/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9972 - loss: 0.0028 - val_accuracy: 0.4294 - val_loss: 5.9012\n",
      "Epoch 169/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - accuracy: 0.9972 - loss: 0.0037 - val_accuracy: 0.4315 - val_loss: 5.8859\n",
      "Epoch 170/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9977 - loss: 0.0029 - val_accuracy: 0.4301 - val_loss: 5.9736\n",
      "Epoch 171/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9976 - loss: 0.0037 - val_accuracy: 0.4280 - val_loss: 5.9892\n",
      "Epoch 172/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9979 - loss: 0.0023 - val_accuracy: 0.4322 - val_loss: 6.0053\n",
      "Epoch 173/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9954 - loss: 0.0041 - val_accuracy: 0.4244 - val_loss: 6.0452\n",
      "Epoch 174/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9972 - loss: 0.0049 - val_accuracy: 0.4301 - val_loss: 5.9841\n",
      "Epoch 175/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - accuracy: 0.9986 - loss: 0.0020 - val_accuracy: 0.4308 - val_loss: 5.9837\n",
      "Epoch 176/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9980 - loss: 0.0028 - val_accuracy: 0.4308 - val_loss: 6.0376\n",
      "Epoch 177/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - accuracy: 0.9975 - loss: 0.0033 - val_accuracy: 0.4301 - val_loss: 6.0770\n",
      "Epoch 178/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9977 - loss: 0.0032 - val_accuracy: 0.4294 - val_loss: 6.1408\n",
      "Epoch 179/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 502us/step - accuracy: 0.9959 - loss: 0.0063 - val_accuracy: 0.4357 - val_loss: 5.0603\n",
      "Epoch 180/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9754 - loss: 0.0676 - val_accuracy: 0.4350 - val_loss: 4.3741\n",
      "Epoch 181/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - accuracy: 0.9908 - loss: 0.0224 - val_accuracy: 0.4400 - val_loss: 5.2481\n",
      "Epoch 182/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.9957 - loss: 0.0064 - val_accuracy: 0.4280 - val_loss: 5.5246\n",
      "Epoch 183/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - accuracy: 0.9979 - loss: 0.0027 - val_accuracy: 0.4251 - val_loss: 5.5798\n",
      "Epoch 184/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - accuracy: 0.9979 - loss: 0.0033 - val_accuracy: 0.4280 - val_loss: 5.6499\n",
      "Epoch 185/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - accuracy: 0.9969 - loss: 0.0035 - val_accuracy: 0.4287 - val_loss: 5.7137\n",
      "Epoch 186/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - accuracy: 0.9976 - loss: 0.0030 - val_accuracy: 0.4294 - val_loss: 5.7459\n",
      "Epoch 187/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - accuracy: 0.9969 - loss: 0.0029 - val_accuracy: 0.4301 - val_loss: 5.8014\n",
      "Epoch 188/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 470us/step - accuracy: 0.9968 - loss: 0.0031 - val_accuracy: 0.4294 - val_loss: 5.8157\n",
      "Epoch 189/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - accuracy: 0.9958 - loss: 0.0039 - val_accuracy: 0.4280 - val_loss: 5.8792\n",
      "Epoch 190/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9972 - loss: 0.0035 - val_accuracy: 0.4273 - val_loss: 5.9353\n",
      "Epoch 191/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481us/step - accuracy: 0.9981 - loss: 0.0034 - val_accuracy: 0.4287 - val_loss: 5.9580\n",
      "Epoch 192/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448us/step - accuracy: 0.9976 - loss: 0.0030 - val_accuracy: 0.4294 - val_loss: 6.0004\n",
      "Epoch 193/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - accuracy: 0.9980 - loss: 0.0040 - val_accuracy: 0.4294 - val_loss: 6.0481\n",
      "Epoch 194/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 462us/step - accuracy: 0.9970 - loss: 0.0027 - val_accuracy: 0.4294 - val_loss: 6.0521\n",
      "Epoch 195/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473us/step - accuracy: 0.9974 - loss: 0.0024 - val_accuracy: 0.4329 - val_loss: 5.8191\n",
      "Epoch 196/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - accuracy: 0.9868 - loss: 0.0347 - val_accuracy: 0.4251 - val_loss: 5.2352\n",
      "Epoch 197/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.9873 - loss: 0.0307 - val_accuracy: 0.4357 - val_loss: 5.4188\n",
      "Epoch 198/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - accuracy: 0.9944 - loss: 0.0104 - val_accuracy: 0.4364 - val_loss: 5.5178\n",
      "Epoch 199/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 455us/step - accuracy: 0.9973 - loss: 0.0044 - val_accuracy: 0.4329 - val_loss: 5.7231\n",
      "Epoch 200/200\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - accuracy: 0.9975 - loss: 0.0037 - val_accuracy: 0.4336 - val_loss: 5.8024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7586b68a5b80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train_cat, epochs=200, batch_size=32, validation_data=(X_test, y_test_cat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 570us/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on the test data\n",
    "y_pred_cat = model.predict(X_test)\n",
    "\n",
    "# Convert predictions back to labels\n",
    "y_pred = y_pred_cat.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.47      0.45       715\n",
      "           1       0.42      0.40      0.41       701\n",
      "\n",
      "    accuracy                           0.43      1416\n",
      "   macro avg       0.43      0.43      0.43      1416\n",
      "weighted avg       0.43      0.43      0.43      1416\n",
      "\n",
      "Confusion Matrix:\n",
      "[[334 381]\n",
      " [421 280]]\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLProj1env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
