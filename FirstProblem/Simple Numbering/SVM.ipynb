{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Read the data from 'train_emoticon.csv'\n",
    "# Assuming the CSV file has no header and columns are 'emoji_sequence' and 'label'\n",
    "df = pd.read_csv('/home/belief/Desktop/MLProj1/mini-project-1/datasets/train/train_emoticon.csv')\n",
    "# Step 2: Split each emoji sequence into individual emojis\n",
    "# Use regex to handle emojis correctly\n",
    "def split_emojis(emoji_sequence):\n",
    "    # Use the regex pattern \\X to match grapheme clusters (i.e., emojis)\n",
    "    return re.findall(r'\\X', emoji_sequence)\n",
    "# Apply the function to create a new column with the list of emojis\n",
    "df['emoji_list'] = df['input_emoticon'].apply(split_emojis)\n",
    "# Verify that all sequences have 13 emojis\n",
    "sequence_lengths = df['emoji_list'].apply(len)\n",
    "if not all(sequence_lengths == 13):\n",
    "    # Find rows with incorrect sequence lengths\n",
    "    incorrect_lengths = df[sequence_lengths != 13]\n",
    "    print(\"Warning: The following rows do not have 13 emojis:\")\n",
    "    print(incorrect_lengths)\n",
    "    # Optionally, handle these rows (e.g., drop them or pad/truncate the sequences)\n",
    "    # For now, we'll proceed but you may need to address this\n",
    "# Step 3: Collect all unique emojis and assign a unique numerical ID to each\n",
    "# Flatten the list of emoji lists to get all emojis\n",
    "all_emojis = [emoji for emoji_list in df['emoji_list'] for emoji in emoji_list]\n",
    "unique_emojis = sorted(set(all_emojis))\n",
    "emoji_to_id = {emoji: idx for idx, emoji in enumerate(unique_emojis)}\n",
    "# Save the mapping to a file (optional)\n",
    "with open('emoji_mapping.txt', 'w', encoding='utf-8') as f:\n",
    "    for emoji, idx in emoji_to_id.items():\n",
    "        f.write(f'{emoji}: {idx}\\n')\n",
    "# Step 4: Replace the emojis in the data with the assigned numbers\n",
    "# Convert each emoji in the list to its corresponding ID\n",
    "def emojis_to_ids(emoji_list):\n",
    "    return [emoji_to_id[emoji] for emoji in emoji_list]\n",
    "\n",
    "df['emoji_ids'] = df['emoji_list'].apply(emojis_to_ids)\n",
    "# Expand the emoji IDs into separate columns\n",
    "emoji_columns = [f'emoji_{i+1}' for i in range(13)]\n",
    "emoji_ids_df = pd.DataFrame(df['emoji_ids'].tolist(), columns=emoji_columns)\n",
    "# Combine the emoji ID columns with the label\n",
    "df = pd.concat([emoji_ids_df, df['label']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      emoji_1  emoji_2  emoji_3  emoji_4  emoji_5  emoji_6  emoji_7  emoji_8  \\\n",
      "0          26      198       58       16       34       93      106      179   \n",
      "1         198       16       41       26      179      106       34      126   \n",
      "2          26      106       16      154       34      179      198      109   \n",
      "3          26      179      198       78       34      106       16      102   \n",
      "4         198      152      179       26       73       16       34      106   \n",
      "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "7075      106       57       58       16       34      198       26      179   \n",
      "7076      198      179        5      106       34      115       26       16   \n",
      "7077      209       16       80       26       34      106      198      179   \n",
      "7078       34       16       26      193      198      106      179      163   \n",
      "7079       26       34      179       16      198       56      106      165   \n",
      "\n",
      "      emoji_9  emoji_10  emoji_11  emoji_12  emoji_13  label  \n",
      "0          17       117        16       106        34      0  \n",
      "1          16       106        56        34       117      0  \n",
      "2          34       106       199        16       117      0  \n",
      "3          16       117       188        34       106      1  \n",
      "4          56       106        16        34       117      1  \n",
      "...       ...       ...       ...       ...       ...    ...  \n",
      "7075      117       106        34        16       153      1  \n",
      "7076       16       117        34       134       106      1  \n",
      "7077      117       104       106        34        16      1  \n",
      "7078      106        16       183        34       117      0  \n",
      "7079       16        34       152       106       117      0  \n",
      "\n",
      "[7080 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and labels\n",
    "X = df.drop('label', axis=1)  # Features: all columns except 'label'\n",
    "y = df['label']               # Target variable: 'label' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature scaling\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial SVM training\n",
    "clf = svm.SVC(kernel='rbf')  # You can experiment with 'rbf', 'poly', etc.\n",
    "clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = clf.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial evaluation\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning with Grid Search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'kernel': ['linear', 'rbf', 'poly']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation with the best estimator\n",
    "best_clf = grid.best_estimator_\n",
    "y_pred = best_clf.predict(X_test_scaled)\n",
    "\n",
    "print(\"Accuracy after tuning:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLProj1env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
